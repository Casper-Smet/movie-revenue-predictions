{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "# SciKit-Learn packages\n",
    "from sklearn.metrics import precision_score, accuracy_score, hamming_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "\n",
    "# Stop words for NLP\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# For detecting English\n",
    "from langdetect import detect\n",
    "\n",
    "# Custom functions used in Q2\n",
    "from Q2Funcs import find_uniques, one_hot, column_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  In hoeverre is het mogelijk om op basis van plot keywords te voorspellen tot welke genres een film behoort?\n",
    "# Casper\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_movies = pd.read_csv('../../data/movie.csv')\n",
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genres = pd.read_csv('../../data/imdb/movies_genres.csv', delimiter='\\t')\n",
    "df_genres.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data processing \n",
    "Alleen 'keywords' en 'genres' nodig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ongewenste kolommen verwijderen\n",
    "df_movies.drop([\"movie_imdb_link\", \"aspect_ratio\"], axis=1, inplace=True)\n",
    "\n",
    "#Onduidelijke kolomnamen aanpassen\n",
    "df_movies.rename(columns={'color': 'Colour',\n",
    "                          'director_name': 'Director',\n",
    "                          'num_critic_for_reviews': 'Number of critics',\n",
    "                          'duration': 'Duration',\n",
    "                          'director_facebook_likes': 'Director FB likes',\n",
    "                          'actor_3_facebook_likes': 'Actor 3 FB likes',\n",
    "                          'actor_2_name': 'Actor 2 name',\n",
    "                          'actor_1_facebook_likes': 'Actor 1 FB likes',\n",
    "                          'gross': 'Gross',\n",
    "                          'genres': 'Genres',\n",
    "                          'actor_1_name': 'Actor 1 name',\n",
    "                          'movie_title': 'Movie title',\n",
    "                          'num_voted_users': 'Number of voted users',\n",
    "                          'cast_total_facebook_likes': 'Total Cast FB likes',\n",
    "                          'actor_3_name': 'Actor 3 name',\n",
    "                          'facenumber_in_poster': 'Number of faces on poster',\n",
    "                          'plot_keywords': 'Plot Keywords',\n",
    "                          'num_user_for_reviews': 'Number of user reviews',\n",
    "                          'language': 'Language',\n",
    "                          'country': 'Country',\n",
    "                          'content_rating': 'Age rating',\n",
    "                          'budget': 'Budget',\n",
    "                          'title_year': 'Release year',\n",
    "                          'actor_2_facebook_likes': 'Actor 2 FB likes',\n",
    "                          'imdb_score': 'IMDB Score',\n",
    "                          'movie_facebook_likes': 'Movie FB likes'}, inplace=True)\n",
    "\n",
    "# Volgorde kolommen aanpassen\n",
    "df_movies = df_movies[['Movie title',\n",
    "                       'Release year',\n",
    "                       'Director',\n",
    "                       'Director FB likes',\n",
    "                       'Gross',\n",
    "                       'Budget',\n",
    "                       'Duration',\n",
    "                       'Language',\n",
    "                       'Country',\n",
    "                       'Colour',\n",
    "                       'Genres',\n",
    "                       'IMDB Score',\n",
    "                       'Number of voted users',\n",
    "                       'Number of critics',\n",
    "                       'Number of user reviews',\n",
    "                       'Age rating',\n",
    "                       'Total Cast FB likes',\n",
    "                       'Movie FB likes',\n",
    "                       'Actor 1 name',\n",
    "                       'Actor 2 name',\n",
    "                       'Actor 3 name',\n",
    "                       'Actor 1 FB likes',\n",
    "                       'Actor 2 FB likes',\n",
    "                       'Actor 3 FB likes',\n",
    "                       'Plot Keywords',\n",
    "                       'Number of faces on poster',\n",
    "                       ]]\n",
    "\n",
    "# Datatypen aanpassen\n",
    "# 1. Floats omzetten naar integers\n",
    "#  De dataset bevat geen kolommen die dienen te worden bewaard als float, behalve `IMDB Score`\n",
    "df_movies_IMDB_Score = df_movies[\"IMDB Score\"]  # Tijdelijke kopie van de kolom `IMDB Score`\n",
    "df_movies = df_movies.drop('IMDB Score', axis=1).fillna(0).astype(int, errors='ignore') # Waarden omzetten naar integers\n",
    "df_movies.insert(11, \"IMDB Score\", df_movies_IMDB_Score)  # `IMDB Score` weer toevoegen aan originele DataFrame\n",
    "del df_movies_IMDB_Score\n",
    "\n",
    "# 2. De kolom `Release year` omzettten van integers naar het datetime-datatype\n",
    "df_movies[\"Release year\"] = pd.to_datetime(df_movies[\"Release year\"], format='%Y', errors='coerce')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# NaN-types verwijderen\n",
    "df_movies.dropna(inplace=True)\n",
    "\n",
    "# Dubbele titels verwijderen\n",
    "df_movies.sort_values(\"Release year\", inplace=True)  # Sorteren op uitgavejaar\n",
    "df_movies.drop_duplicates(subset=\"Movie title\", keep=\"last\", inplace=True)  # Alleen meest recente versie blijft bewaard\n",
    "\n",
    "# Negatieve waardes verwijderen\n",
    "num = df_movies._get_numeric_data()\n",
    "num[num < 0] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Genres voorspellen gebaseerd op Plot Keywords\n",
    "De onderzoeksvraag gaat als volgt: \n",
    "> In hoeverre is het mogelijk om op basis van plot keywords te voorspellen tot welke genres een film behoort? \n",
    "\n",
    "\n",
    "### Q2. Data collection\n",
    "Bij `Q2` wordt er gebruik gemaakt van de kolommen `Genres` en `Plot Keywords` uit `df_movies`. Om ervoor te zorgen dat bij andere onderzoeksvragen de DataFrame niet onnodig wordt aangepast, wordt de dataframe voor de zekerheid als een kopie aangeroepen. \n",
    "\n",
    "Ook wordt het model aan het einde van het hoofdstuk getest in een andere scenario. Er wordt getest vanuit de plot beschrijving (I.E. een alinea lange beschrijving van het plot) in plaats van plot keywords. Deze data wordt tegelijkertijd met `DF_Q2` verwerkt tot een X en een Y.\n",
    "\n",
    "Deze extra data komt van [Document Classification](http://www.davidsbatista.net/blog/2017/04/01/document_classification/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Q2 = df_movies.loc[:, (\"Genres\", \"Plot Keywords\")].copy()\n",
    "df_Q2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Data processing\n",
    "Aangezien vrijwel alle machine learning algoritmen alleen algebraïsche datatypes accepteren, moeten zowel `Plot Keywords` als `Genres` ingrijpend veranderd worden. Beide zijn namelijk categoriale datatypes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2. Cleaning voor processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Na een korte inspectie van de data, kom je een aantal waardes van 0 en “0” tegen (`int` en `string`). Dit zijn missende waarden. \n",
    "\n",
    "Hoewel dit gewoonlijks in stap 3 van het Data Science proces gebeurt, is het in deze scenario beter om dit van tevoren te doen. De 0 en \"0\" zijn na deze stap namelijk moeilijker terug te vinden.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All '0' are missing values, remove\n",
    "df_Q2.replace(\"0\", np.NaN, inplace=True)\n",
    "df_Q2.replace(0, np.NaN, inplace=True)\n",
    "df_Q2.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2. Terug naar processing\n",
    "Om in de gebruikte modellen gebruik te maken van `Genres` en `Plot Keywords` moeten deze gecodeerd worden. \n",
    "\n",
    "Om dit te doen moeten de kolommen eerst gesplitst worden. Dit gaat op twee manieren. \n",
    "\n",
    "Van `Genres` wordt een lijst gemaakt, alle genres zijn namelijk opgebroken met behulp van een `|`. Dit resulteerd in de kolom `Split Genres`. Hetzelfde proces wordt toegepast bij `Plot Keywords`. Dit resulteerd in de kolom `Split Keywords`.\n",
    "\n",
    "Bij `Plot Keywords` worden alle `|` vervangen met een spatie. Dit wordt later verder toegelicht.\n",
    "\n",
    "Hoewel `Split Keywords` niet wordt gebruikt als input variabele, is deze alsnog handig om te hebben bij het analyseren van de data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split \"Genres\" by \"|\", creating list types\n",
    "df_Q2.loc[:, \"Split Genres\"] = df_Q2[\"Genres\"].str.split(pat=\"|\")\n",
    "\n",
    "# Replace \"|\" with \" \" to create strings analysable by TF-IDf.\n",
    "df_Q2.loc[:, \"Plot Keywords\"] = df_Q2[\"Plot Keywords\"].str.replace(\"|\", \" \")\n",
    "# Split \"Plot Keywords\" by \" \", creating list types\n",
    "df_Q2.loc[:, \"Split Keywords\"] = df_Q2[\"Plot Keywords\"].str.split(pat=\" \")\n",
    "\n",
    "\n",
    "df_Q2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([df_Q2[\"Split Genres\"].str.len().describe(), df_Q2[\"Split Keywords\"].str.len().describe()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Er zijn gemiddeld drie genres en vijf plot keywords per film. Het is echter géén uniforme data. Zowel genres als plot keywords heeft een minimum van 1 woord (I.E. er is maar één genre of één plot keyword). Het maximaal aantal waarden voor genres is 8, het maximaal aantal waarden voor plot keywords is daarentegen 25. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Een probleem met de vraagstelling is dat genres multilabel waardes zijn, een film dus heeft meer dan een genre. Alleen het eerste genre pakken is een mogelijkheid, maar dit zal de accuratesse van ons model zeer negatief beïnvloeden. De genres zijn namelijk niet gesorteerd op toepasbaarheid, maar alfabetisch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabetical = True\n",
    "for value in df_Q2[\"Split Genres\"].values:\n",
    "    if value != sorted(value):\n",
    "        alphabetical = False\n",
    "        \n",
    "alphabetical\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zowel genres als plot keywords is categorische data. Aangezien meeste machine learning modellen algebraïsch zijn, accepteren deze alleen numerieke data. Dat betekent dat zowel genres als keywords omgezet moet worden naar numerieke data. \n",
    "\n",
    "Dit wordt meestal doormiddel van ‘One-Hot’ encoding gedaan. Bij 'One-Hot' encoding wordt van iedere unieke waarde een eigen kolom gemaakt. Deze kolom heeft een waarde '1' of '0'. Of de waarde komt voor in `Genres`, of niet.\n",
    "\n",
    "Dit veroorzaakt echter een probleem wanneer er sprake is van een grote variatie aan herhalende data. In deze scenario kan term frequency-inverse document frequency (TF-IDF) gebruikt worden.\n",
    "\n",
    "TF-IDF genereerd namelijk waardes en kolommen gebaseerd op de frequentie van woorden in een string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De volgende stap is om te kijken naar unieke waarden van zowel `Genres` als `Plot Keywords`. Gebaseerd op het aantal unieke waarden wordt de de codeertechniek gekozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_uniques = find_uniques(df_Q2[\"Split Genres\"])\n",
    "genre_uniques.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het gaat hierbij dus om 24 unieke genres. Ook zullen genres niet meer dan één keer in een rij voorkomen. Bij `Genres` zal dus One-Hot encoding gebruikt worden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_uniques = find_uniques(df_Q2[\"Split Keywords\"])\n",
    "key_uniques.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Er zijn in totaal 6104 unieke plot keywords. Bepaalde plot keywords zullen ook meerdere keren per rij voor kunnen komen. Bij `Plot Keywords` zal dus TF-IDF gebruikt worden.\n",
    "#### Q2 Coderen van categoriale data\n",
    "Beginnend met `Genres`, deze kolom wordt gecodeerd met behulp van One-Hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_Q2 = one_hot(df_Q2, \"Split Genres\")\n",
    "Y = df_Q2.loc[:, \"Drama\" : ]\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten tweede coderen we `Plot Keywords`, deze kolom wordt gecodeerd met behulp van TF-IDF. \n",
    "TF-IDF kan ook veel gebruikte, maar weinig zeggende woorden (`stop words`) als ‘of’ en ‘and’ uit een tekst halen. Deze worden direct door de TF-IDF-vectorizer van Scikit-learn geëxtraheerd. Hierdoor neemt het aantal kolommen significant af.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(stop_words=stop_words)\n",
    "X = vec.fit_transform(df_Q2[\"Plot Keywords\"])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Hoewel 5994 kolommen nog steeds veel is, bespaar je als nog erg veel in vergelijking tot 6104 kolommen.\n",
    "\n",
    "#### Q2. Processing van extra dataset\n",
    "\n",
    "De data van genres staat al One-Hot gecodeerd. Er zijn hier echter wel meer genres dan bij de originele dataset. De extra genres moeten dus verwijderd worden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_genres = df_genres[np.intersect1d(Y.columns.values, df_genres.columns.values)].copy()\n",
    "Y_genres.columns.size, Y.columns.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Er mist nu nog één genre in `Y_genres`. Deze zal overal gelijk staan aan 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_genre = np.setdiff1d(Y.columns.values, Y_genres.columns.values)\n",
    "print(\"Missing genre:\", missing_genre[0])\n",
    "Y_genres.loc[:, missing_genre[0]] = 0\n",
    "Y_genres = Y_genres[Y.columns.values]\n",
    "Y_genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_genres.columns == Y.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vervolgens moet ook de X van `DF_genres` verwerkt worden. Bij de bron van de dataset moet er eerst gefilterd worden op taal. Hier is dat niet nodig, aangezien de TF-IDF vectorizer gefit is op een Engelse dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_genres = vec.transform(df_genres[\"plot\"])\n",
    "X_genres.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Data cleaning\n",
    "Al het Data Cleaning is voor deze stap al gedaan, namelijk in de paragrafen `3. Data Cleaning` en `Q2. Cleaning voor processing`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Data Exploration & Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu is een goed moment om te kijken naar de X en Y (noteer de hoofdletter bij Y, de output is namelijk ook een matrix). Beginnend met de X.\n",
    "\n",
    "De X moet wel eerst omgevormd worden naar een NumPy array. X wordt nu namelijk nog opgeslagen in de vorm van een sparse array. Dit om ruimte in het geheugen te besparen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(X.toarray(), columns=vec.get_feature_names()).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier valt al direct een probleem te ontdekken, de waardes gegenereerd door TF-IDF liggen redelijk laag. Dit betekent dat er niet veel van dezelfde woorden langskomen. Dit kán mogelijk de waarde van de voorspellingen negatief beïnvloeden. Hier wordt echter tot zekere hoogte rekening mee gehouden met behulp van het gebruik van `stop_words`.\n",
    "\n",
    "Vervolgens de Y. Aangezien er een eigen One-Hot functie geschreven is, wordt Y niet opgeslagen in de vorm van een sparse array. Y is in de vorm van een DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aangezien alle waarden of `1` of `0` zijn, staat het gemiddelde ook gelijk aan het percentage films dit genre tot behoort. Zowel té hoog als té laag zal waarschijnlijk een slechte invloed hebben op de voorspellingen. \n",
    "\n",
    "Aangezien iets meer dan 50% van de films behoren tot het genre `Drama` behoren, zal er waarschijnlijk sprake zijn van veel false positives. \n",
    "\n",
    "Ook zijn er een groot aantal genres waar minder dan 5% van de films tot behoren. Aangezien hier relatief weinig data van is, zal het verbanden vinden tussen plot keywords en deze genres aanzienlijk moeilijker zijn. Waarschijnlijk zal er sprake zijn van veel false negatives. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra data set\n",
    "Tenslotte wordt er ook nog gekeken naar het aantal films per genre bij de extra dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_extra = pd.DataFrame(Y_genres.sum(), columns=[\"Count\"])\n",
    "unique_extra.reset_index(inplace=True)\n",
    "unique_extra.columns = [\"Split Genres\", \"Test Count\"]\n",
    "# unique_extra[\"Train Count\"] = genre_uniques[\"Count\"]\n",
    "unique_extra = unique_extra.merge(genre_uniques)\n",
    "unique_extra.columns = [\"Split Genres\", \"Test Count\", \"Train Count\"]\n",
    "unique_extra.sort_values(\"Test Count\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Model building\n",
    "\n",
    "\n",
    "Films zoals “[Bad Boys](https://www.imdb.com/title/tt0112442/?ref_=ttkw_kw_tt)” met genres als ‘Action, Comedy, Crime’ zullen dan alleen geclassificeerd worden als ‘Action’. [Plot keywords](https://www.imdb.com/title/tt0112442/keywords?ref_=tt_ql_stry_4) zoals ‘evil man’ en ‘firearm’ komen dan nog goed overeen met het genre, maar plot keywords als ‘buddy movie’ en ‘buddy comedy’ niet.\n",
    "\n",
    "Om dit op te lossen, moet er gebruik gemaakt worden van ‘multi-label classification’. Dit is niet te verwarren met ‘multi-class classification’. Bij multi-label is er sprake van meerdere labels die tegelijkertijd toepasbaar kunnen zijn, bij multi-class is er altijd maar één klasse(label) toepasbaar.\n",
    "\n",
    "\n",
    "Er worden voor deze onderzoeksvraag drie modellen toegelicht.\n",
    "\n",
    "Ieder model wordt op drie manieren getest:\n",
    "* Accuracy Score per genre (> == beter)\n",
    "* Precision Score per genre (> == beter)\n",
    "* Hamming loss op de gehele voorspelling (< == beter)\n",
    "\n",
    "Tenslotte wordt de hoeveelheid films per genre als extra kolom toegevoegd.\n",
    "\n",
    "Ten eerste, het opsplitsen in `test` en `train` datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=42)\n",
    "print(\"Train:\", X_train.shape, Y_train.shape)\n",
    "print(\"Test:\", X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2. Imiteren met behulp van Multi-Class predictions\n",
    "Eén methode om multi-label te implementeren, is om dit niet te doen. In plaats van “echte” multi-label classificatie te gebruiken, imiteer je het met behulp van Multi-Class classificatie. Voor iedere klasse train en test je het model apart. Dit komt echter met een forse performance hit. Ook zorgt dit ervoor dat voor iedere test set opnieuw het model moet laten fitten.\n",
    "\n",
    "Qua model wordt er hier gebruik gemaakt van een Multinomial Naive Bayesian model, met daar omheen een veel gebruikte Multi-Class wrapper (OneVsRest). Multinomial Naive Bayesian is vrijwel de standaard voor text classificatie, en zal waarschijnlijk het eerste resultaat zijn indien je text classificatie googled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_pipeline = Pipeline([\n",
    "                ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "                    fit_prior=True, class_prior=None))),\n",
    "            ])\n",
    "\n",
    "predictions = []\n",
    "for genre in genre_uniques[\"Split Genres\"]:\n",
    "    NB_pipeline.fit(X_train, Y_train[genre])\n",
    "    predictions.append(NB_pipeline.predict(X_test))\n",
    "   \n",
    "predictions = np.array(predictions).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hamming loss:\", hamming_loss(Y_test, predictions))\n",
    "column_score(Y_test, predictions).merge(genre_uniques, left_on=\"Category\", right_on=\"Split Genres\").drop(\"Split Genres\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De waarde van de voorspelling lijkt beter te worden naarmate het aantal films per genre het gemiddeld aantal films per genre (564, zie Q2. Data processing) bereikt. Zodra het aantal films hier ruim onder begint te komen, voorspelt dit model dat alle films tot die genres behoren.\n",
    "\n",
    "De Hamming loss van dit model ligt erg laag, op ongeveer 0.11. Dat betekent dat de voorspeling van redelijk goede kwaliteit is.  \n",
    "\n",
    "\n",
    "#### Q2. Binary Relevance en Naive Bayes classifiers\n",
    "De tweede methode om multi-label classification toe te passen, heet Binary Relevance. Dit valt beter uit te leggen met behulp van een voorbeeld. Zie daarvoor de volgende paragraaf. Binary Relevance is op moment van schrijven nog niet opgenomen in het officiële Scikit-Learn library. Om dit te kunnen gebruiken is de Scikit-Learn addon ` skmultilearn` benodigd.\n",
    "##### Multinomial\n",
    "Hieronder wordt net zoals bij `Q2. Imiteren met behulp van Multi-Class predictions` gebruik gemaakt van Multinomiale Naive Bayesian classificatie. Met de `BinaryRelevance` wrapper van `skmultilearn` er omheen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNB_classifier = BinaryRelevance(MultinomialNB())\n",
    "MNB_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = MNB_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Hamming loss:\", hamming_loss(Y_test, predictions))\n",
    "df_MNB_score = column_score(Y_test, predictions).merge(genre_uniques, left_on=\"Category\", right_on=\"Split Genres\").drop(\"Split Genres\", axis=1)\n",
    "df_MNB_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De resultaten van Binary Relevance op Multinomial NB zijn exact hetzelfde als de resultaten resultaten van de eerder gebruikte pipeline. \n",
    "\n",
    "Binary Relevance valt binnen multi-label machine learning in het groepje `Problem transformation approaches`. Het pakt een multi-label probleem, en splitst deze op in kleinere problemen die op te lossen zijn met behulp van al bestaande technieken. \n",
    "Een nadeel hiervan is echter wel dat de verbanden tússen de verschillende labels buiten beschouwing raken. Het resultaat is desalniettemin beter dan verwacht.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gaussian naive bayes\n",
    "\n",
    "Een tweede model dat regelmatig wordt gebruikt voor het classificeren van tekst, is het Gaussian Naive Bayes model. Dit gaat uit van een normaalverdeling in plaats van een multinomiale verdeling.\n",
    "\n",
    "Gaussian is meestal een aanzienlijk slechtere methode om tekst mee te classificeren, het wordt bij deze onderzoeksvraag alleen gebruikt om de kwaliteit van Multinomial Naive Bayes beter te laten zien.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GNB_classifier = BinaryRelevance(GaussianNB())\n",
    "GNB_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = GNB_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hamming loss:\", hamming_loss(Y_test, predictions))\n",
    "df_GNB_score = column_score(Y_test, predictions).merge(genre_uniques, left_on=\"Category\", right_on=\"Split Genres\").drop(\"Split Genres\", axis=1)\n",
    "df_GNB_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoals verwacht is de voorspelling minder accuraat dan die van Multinomial NB. De voorspelling is echter wel beter dan verwacht. Het is beter in het voorspellen van de waardes die onder het gemiddelde vallen dan Multinomial NB, voor alle andere waarden lijkt het echter slechter te zijn. \n",
    "\n",
    "Tenslotte zijn de laatste drie genres (Film-Noir, Short & News) alle drie nog steeds niet mogelijk om te voorspellen.\n",
    "\n",
    "#### Q2. Model testing; Extra dataset\n",
    "\n",
    "Tenslotte wordt dezelfde voorspelling nog een keer uitgevoerd op de extra dataset. Hier wordt weer gebruik gemaakt van de Multinomial Naive Bayesian classifier uit `Q2. Multinomial`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = MNB_classifier.predict(X_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hamming loss:\", hamming_loss(Y_genres, predictions))\n",
    "df_extra_score = column_score(Y_genres, predictions).merge(unique_extra, left_on=\"Category\", right_on=\"Split Genres\").drop(\"Split Genres\", axis=1)\n",
    "df_extra_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoewel de Hamming loss lager is dan bij de andere voorspellingen, is de precision score aanzienlijk slechter. De mindere waarde is op een paar manieren te verklaren.\n",
    "\n",
    "De grootte van de originele dataset was te klein om op te trainen. Deze externe dataset is completer, maar daar wordt geen rekening mee gehouden bij het TF-IDF-proces. Er zullen waarschijnlijk veel termen voorkomen in de externe dataset, die niet voorkomen in de originele dataset.\n",
    "\n",
    "De aard van de externe data is anders dan van het origineel. De externe data bestaat uit een uitgebreide beschrijving van het plot. De originele dataset bevat meerdere enkele termen of korte zinnen. Het kan zijn dat ‘keywords’ zodanig anders zijn dan een beschrijving van het plot, dat dat de voorspelling aanzienlijk negatief beïnvloed.\n",
    "\n",
    "Het lijkt echter wel dat deze voorspelling hetzelfde pattern volgt als de voorspelling op de testdata. De precision wordt langzamerhand beter totdat deze het genre met het gemiddeld aantal films bereikt. Wanneer het onder dit gemiddelde valt, wordt de precision score 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Visualization\n",
    "Om een beter beeld te geven van de verbanden tussen het aantal films per genre, en hun accuracy- en precision scores, worden deze samen geplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_MNB_ac = hv.Scatter(df_MNB_score[[\"Count\", \"Accuracy Score\"]]).opts(title=\"MNB\", ylim=(-0.05, 1.05), xlim=(-100, 2500), size=5)\n",
    "sc_GNB_ac = hv.Scatter(df_GNB_score[[\"Count\", \"Accuracy Score\"]]).opts(title=\"GNB\", ylim=(-0.05, 1.05), xlim=(-100, 2500), size=5)\n",
    "sc_extra_ac = hv.Scatter(df_extra_score[[\"Train Count\", \"Accuracy Score\"]]).opts(title=\"Extra MNB\", ylim=(-0.05, 1.05), xlim=(-100, 2500), size=5)\n",
    "\n",
    "\n",
    "sc_MNB_pr = hv.Scatter(df_MNB_score[[\"Count\", \"Precision Score\"]]).opts(title=\"MNB\", ylim=(-0.05, 1.05), xlim=(-100, 2500), size=5)\n",
    "sc_GNB_pr = hv.Scatter(df_GNB_score[[\"Count\", \"Precision Score\"]]).opts(title=\"GNB\", ylim=(-0.05, 1.05), xlim=(-100, 2500), size=5)\n",
    "sc_extra_pr = hv.Scatter(df_extra_score[[\"Train Count\", \"Precision Score\"]]).opts(title=\"Extra MNB\", ylim=(-0.05, 1.05), xlim=(-100, 2500), size=5)\n",
    "\n",
    "\n",
    "(sc_MNB_pr + sc_GNB_pr + sc_extra_pr + sc_MNB_ac + sc_GNB_ac + sc_extra_ac).cols(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Communication\n",
    "#### Q2. Definitieve pipeline\n",
    "De definitieve pipeline van dit project is de `MNB_classifier`. De Binary Relevance Multinomial Naive Bayesian classifier. Van de twee classificatie modellen, geeft deze betere voorspellingen.\n",
    "#### Q2. Conclusie\n",
    "De onderzoeksvraag die beantwoord wordt met behulp van dit model ging als volgt:\n",
    "> In hoeverre is het mogelijk om op basis van plot keywords te voorspellen tot welke genres een film behoort?\n",
    "\n",
    "Het is zeer goed mogelijk om op basis van plot keywords te voorspellen tot welke genres een film behoort. Er zijn echter wel een paar dingen waar, bij dit model, rekening mee gehouden moet worden. \n",
    "Ten eerste is het model, met de huidige training data, niet goed in het voorspellen van genres met minder dan 515 datapunten. Dat houdt dat maar 10 van de 24 genres correct voorspeld kunnen worden. \n",
    "\n",
    "De meeste films zullen in principe behoren tot die 10 genres, maar dat betekent niet dat er geen films van die genres bestaan. Bij een dataset van circa 5000 films is dit nog geen groot probleem, bij volledigere datasets (denk aan 100K+) zal dit echter wél voor een probleem veroorzaken.\n",
    "\n",
    "Ten tweede houdt dit model geen rekening met de onderlinge verbanden tussen genres. Een film behorend tot het genre ‘Biography’ zal vaak ook behoren tot het genre ‘Documentary’. \n",
    "\n",
    "#### Q2. Mogelijk vervolg onderzoeken\n",
    "\n",
    "Bij een mogelijk vervolgonderzoek komen een aantal dingen aan bod. Ten eerste zou dit onderzoek opnieuw uitgevoerd moeten worden op een andere, grotere dataset. \n",
    "\n",
    "Ten tweede zou er gekeken moeten worden naar meer geavanceerde multi-label classificatie methoden die wél rekening houden met de onderlinge verbanden tussen genres.\n",
    "\n",
    "Ten derde zou er gekeken moeten worden naar de verschillen tussen een plot beschrijving (zoals van de externe dataset) en plot keywords (van de originele dataset).\n",
    "\n",
    "\n",
    "#### Q2 Extra leesmateriaal\n",
    "[TF-IDF](http://www.tfidf.com)\n",
    "\n",
    "[Understanding Multi-Label classification model and accuracy metrics](https://medium.com/towards-artificial-intelligence/understanding-multi-label-classification-model-and-accuracy-metrics-1b2a8e2648ca)\n",
    "\n",
    "[Multi Label Text Classification with Scikit-Learn](https://towardsdatascience.com/multi-label-text-classification-with-scikit-learn-30714b7819c5)\n",
    "\n",
    "[Binary relevance for multi-label learning: an overview](https://link.springer.com/article/10.1007/s11704-017-7031-7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
