{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "import math\n",
    "from scipy import stats\n",
    "\n",
    "# SciKit-Learn packages\n",
    "from sklearn.metrics import precision_score, accuracy_score, hamming_loss, mean_squared_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# SciKit-multi-learn\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "\n",
    "\n",
    "\n",
    "# Stop words for NLP\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Custom functions used in Q2\n",
    "from Q2Funcs import find_uniques, one_hot, column_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Revenue Predictions\n",
    "Onderzoeksvragen:\n",
    "1. In hoeverre is de omzet van een film te voorspellen op basis van de populariteit op Facebook en IMDB zelf?\n",
    "2. In hoeverre is het mogelijk om op basis van plot keywords te voorspellen tot welke genres een film behoort?\n",
    "3. In hoeverre is het mogelijk om de budget-winst verhouding te voorspellen?\n",
    "\n",
    "## Het Data Science proces\n",
    "Voor de eerste verkenning is ons gevraagd om de eerste vier stappen uit te voeren:\n",
    "1. Data collection\n",
    "2. Data processing (ook wel data munging)\n",
    "3. Data cleaning\n",
    "4. Data exploration & analysis\n",
    "5. Model building\n",
    "6. Visualization\n",
    "7. Communication\n",
    "\n",
    "## 1. Data Collection\n",
    "De Data Collection is deels al voor ons gedaan. De dataset `movie.csv` is ons aangeleverd. Echter word voor de opdracht \n",
    "gevraagd om deze te combineren met een dataset van derden. Om erachter te komen welke dataset geschikt is om te \n",
    "combineren met `movies.csv`zullen wij deze dataset eerst moeten processen, cleanen en exploren.  \n",
    "\n",
    "Om te zien of de dataset `movie.csv` goed is ingeladen, worden de eerste vijf rijen getoond:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_movies = pd.read_csv('data/movie.csv')\n",
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Externe dataset\n",
    "Onze originele dataset bevat geen data over de schrijvers van deze films. Deze data valt echter wel te reconstrueren met\n",
    "behulp van andere IMDB datasets. Het gaat hierbij om de volgende datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_genres = pd.read_csv('data/imdb/movies_genres.csv', delimiter='\\t')\n",
    "df_genres.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Processing\n",
    "### 2a. Aangeleverde dataset\n",
    "Ook deze stap is grotendeels voor ons gedaan. De data is goed opgeslagen in een `.csv`-bestand en kan direct worden \n",
    "ingelezen in een _Pandas_ DataFrame.\n",
    "\n",
    "Verder rest ons nog de volgende vier stappen:\n",
    "1. Het verwijderen van ongewenste kolommen\n",
    "2. Het aanpassen van onduidelijke kolomnamen\n",
    "3. Het aanpassen van de volgorde van de kolommen\n",
    "4. Het aanpassen van enkele datatypen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "# Ongewenste kolommen verwijderen\n",
    "df_movies.drop([\"movie_imdb_link\", \"aspect_ratio\"], axis=1, inplace=True)\n",
    "\n",
    "#Onduidelijke kolomnamen aanpassen\n",
    "df_movies.rename(columns={'color': 'Colour',\n",
    "                          'director_name': 'Director',\n",
    "                          'num_critic_for_reviews': 'Number of critics',\n",
    "                          'duration': 'Duration',\n",
    "                          'director_facebook_likes': 'Director FB likes',\n",
    "                          'actor_3_facebook_likes': 'Actor 3 FB likes',\n",
    "                          'actor_2_name': 'Actor 2 name',\n",
    "                          'actor_1_facebook_likes': 'Actor 1 FB likes',\n",
    "                          'gross': 'Gross',\n",
    "                          'genres': 'Genres',\n",
    "                          'actor_1_name': 'Actor 1 name',\n",
    "                          'movie_title': 'Movie title',\n",
    "                          'num_voted_users': 'Number of voted users',\n",
    "                          'cast_total_facebook_likes': 'Total Cast FB likes',\n",
    "                          'actor_3_name': 'Actor 3 name',\n",
    "                          'facenumber_in_poster': 'Number of faces on poster',\n",
    "                          'plot_keywords': 'Plot Keywords',\n",
    "                          'num_user_for_reviews': 'Number of user reviews',\n",
    "                          'language': 'Language',\n",
    "                          'country': 'Country',\n",
    "                          'content_rating': 'Age rating',\n",
    "                          'budget': 'Budget',\n",
    "                          'title_year': 'Release year',\n",
    "                          'actor_2_facebook_likes': 'Actor 2 FB likes',\n",
    "                          'imdb_score': 'IMDB Score',\n",
    "                          'movie_facebook_likes': 'Movie FB likes'}, inplace=True)\n",
    "\n",
    "# Volgorde kolommen aanpassen\n",
    "df_movies = df_movies[['Movie title',\n",
    "                       'Release year',\n",
    "                       'Director',\n",
    "                       'Director FB likes',\n",
    "                       'Gross',\n",
    "                       'Budget',\n",
    "                       'Duration',\n",
    "                       'Language',\n",
    "                       'Country',\n",
    "                       'Colour',\n",
    "                       'Genres',\n",
    "                       'IMDB Score',\n",
    "                       'Number of voted users',\n",
    "                       'Number of critics',\n",
    "                       'Number of user reviews',\n",
    "                       'Age rating',\n",
    "                       'Total Cast FB likes',\n",
    "                       'Movie FB likes',\n",
    "                       'Actor 1 name',\n",
    "                       'Actor 2 name',\n",
    "                       'Actor 3 name',\n",
    "                       'Actor 1 FB likes',\n",
    "                       'Actor 2 FB likes',\n",
    "                       'Actor 3 FB likes',\n",
    "                       'Plot Keywords',\n",
    "                       'Number of faces on poster',\n",
    "                       ]]\n",
    "\n",
    "# Datatypen aanpassen\n",
    "# 1. Floats omzetten naar integers\n",
    "#  De dataset bevat geen kolommen die dienen te worden bewaard als float, behalve `IMDB Score`\n",
    "df_movies_IMDB_Score = df_movies[\"IMDB Score\"]  # Tijdelijke kopie van de kolom `IMDB Score`\n",
    "df_movies = df_movies.drop('IMDB Score', axis=1).fillna(0).astype(int, errors='ignore') # Waarden omzetten naar integers\n",
    "df_movies.insert(11, \"IMDB Score\", df_movies_IMDB_Score)  # `IMDB Score` weer toevoegen aan originele DataFrame\n",
    "del df_movies_IMDB_Score\n",
    "\n",
    "# 2. De kolom `Release year` omzettten van integers naar het datetime-datatype\n",
    "df_movies[\"Release year\"] = pd.to_datetime(df_movies[\"Release year\"], format='%Y', errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het DataFrame ziet er nu als volgt uit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning\n",
    "### 3a. Aangeleverde dataset\n",
    "1. Het verwijderen van NaN-types\n",
    "2. Het verwijderen van dubbele filmtitles\n",
    "3. Het verwijderen van negatieve waardes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# NaN-types verwijderen\n",
    "df_movies.dropna(inplace=True)\n",
    "\n",
    "# Dubbele titels verwijderen\n",
    "df_movies.sort_values(\"Release year\", inplace=True)  # Sorteren op uitgavejaar\n",
    "df_movies.drop_duplicates(subset=\"Movie title\", keep=\"last\", inplace=True)  # Alleen meest recente versie blijft bewaard\n",
    "\n",
    "# Negatieve waardes verwijderen\n",
    "num = df_movies._get_numeric_data()\n",
    "num[num < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na stap 3. Data Cleaning ziet het DataFrame er als volgt uit:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Exploration & Analysis\n",
    "\n",
    "Nu de data geprepareerd is kunnen wij onze eerste verkenning gaan uitvoeren. Door middel van describe krijgen we\n",
    "in een oogopslag een duidelijk beeld van het DataFrame `df_movies`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_movies.describe(include = \"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enkele verwachtingen:\n",
    "1. Een film heeft waarschijnlijk meer Facebook likes dan de director.\n",
    "2. De meeste films zullen winst maken\n",
    "3. Het meerendeel van de films zullen in het Engels zijn\n",
    "4. Comedie en Actie zullen waarschijnlijk de meest voorkomende genres zijn.\n",
    "\n",
    "Testen van de verwachtingen:\n",
    "1. Gemiddeld heeft een film meer dan 10x zoveel likes dan een director.\n",
    "2. Gemiddeld brengt een 40 miljoen op en is er een budget van 30 miljoen voor. Echter heeft de opbrengst een\n",
    "standaard deviatie van 65 miljoen en het budget een standaard deviatie van 79 miljoen. Een goede conclusie is nog niet te geven.\n",
    "3. 93.3% van de films zijn in het Engels. Dit is een ruime meerderheid.\n",
    "4. Tegen de verwachtingen in is `Drama` het meest voorkomende genre met 229 maal. Echter valt hier ook nog niks over \n",
    "te zeggen omdat veel films meerdere genres bevatten.\n",
    "\n",
    "Enkele overige observaties:\n",
    "- Het DataFrame bevat nog 4811 (95.4%) van de originele 5043 rijen \n",
    "- `Movie title` bevat zoals beoogd alleen maar nog unieke waarden.\n",
    "- De gemiddelde IMDB Score van een film is 6.5 met een standaard deviatie van 1.1. De laagste en hoogste scores zijn 1.6 resp. 9.3.\n",
    "- Het DataFrame bevat films die uitgegeven zijn tussen 1916 en 2016. Een interval van 100 jaar.\n",
    "- `Actor 3` bestaat uit de meest (3450) verschillende acteurs, gevolgd door `Actor 2 (2962)`en als laatste `Actor 1 (2042)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De tien meest voorkomende Directors en Actor 1's zijn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_movies[\"Director\"].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_movies[\"Actor 1 name\"].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De volgende plots zijn slechts voor de eerste analyse van de data. Uiteraard zullen deze nog uitgebreid en verbeterd worden\n",
    "in de loop van het project. In de volgende scatterplot zijn het budget en de opbrengsten van films geplot. Te zien is dat \n",
    "de meeste films niet meer dan 200 miljoen hebben gekost en niet meer dan 400 miljoen opleveren. Enkele uitschieters daargelaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.title(\"Relatie tussen het budget en de opbrengst van een film.\")\n",
    "plt.xlabel(\"Budget\")\n",
    "plt.ylabel(\"Opbrengst\")\n",
    "plt.xlim(0, 1_000_000_000)\n",
    "plt.ylim(0, 1_000_000_000)\n",
    "plt.xticks(np.arange(0, 1_000_000_000, step=100_000_000))\n",
    "scatter = ax.scatter(\"Budget\", \"Gross\", data=df_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In de volgende grafiek worden de IMDB scores in het verloop van de tijd geplot. Te zien is dat tot ongeveer 1960 de meeste\n",
    "films een cijfer tussen de 6 en 9 scoorden. Vanaf 1980 ontstaan er steeds meer films met lagere IMDB score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.title(\"IMDB Score van films in de loop van de tijd\")\n",
    "plt.xlabel(\"Jaar van uitgave\")\n",
    "plt.ylabel(\"IMDB Score\")\n",
    "plt.ylim(0, 10)\n",
    "plt.yticks(np.arange(0, 10, step=1))\n",
    "scatter = ax.scatter(\"Release year\", \"IMDB Score\", data=df_movies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In de volgende twee boxplots is de spreiding te zien van het budget en de opbrengsten van alle films. Te zien is dat \n",
    "het budget van films relatef minder is verspreid dan de opbrengst van de films. De boxplot van de opbrengsten heeft \n",
    "tevens veel meer uitschieters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "plt.suptitle(\"Boxplots van het budget en de opbrengst van films\")\n",
    "ax1.set_xlabel(\"Budget\")\n",
    "ax2.set_xlabel(\"Opbrengst\")\n",
    "ax1.boxplot(df_movies[\"Budget\"])\n",
    "ax2.boxplot(df_movies[\"Gross\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Individuele onderzoeksvragen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md \n"
    }
   },
   "source": [
    "## Q1. Omzet voorspellen op basis van de populariteit\n",
    "De onderzoeksvraag gaat als volgt.\n",
    "\n",
    "> In hoeverre is de omzet van een film te voorspellen op basis van de populariteit op Facebook en IMDB zelf?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bij deze deelvraag is besloten om de volgorde van de datascience process niet aan te houden. Dat past beter bij deze deelvraag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Data collection\n",
    "\n",
    "Voor deze onderzoeksvragen wordt er gebruik gemaakt van de volgende features uit `df_movies`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Alleen facebook kolommen of IMDB kolommen nodig\n",
    "features = ['Director FB likes', 'Actor 1 FB likes', \n",
    "                'Actor 2 FB likes', 'Gross', 'Total Cast FB likes',\n",
    "                'Actor 3 FB likes', 'IMDB Score', 'Movie FB likes']\n",
    "df_Q1 = df_movies.copy()[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Data Cleaning\n",
    "\n",
    "Een gedeelte hiervan hebben we in ```3. Data Cleaning``` gedaan. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vervolgens moet alle films zonder omzet verwijderd worden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_Q1 = df_Q1[df_Q1.Gross != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Data Exploration & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_Q1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Er zitten grote verschillen tussen waardes van elke kolom. Aangezien machine learning algoritmes algebraïsche zijn betekend dat een hoog getal meer invloed heeft dan een laag getal. Om dit te voorkomen moet de waardes genormaliseerd worden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volgende stap is proberen (lineaire) correlaties te vinden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.matshow(df_Q1.corr())\n",
    "plt.show()\n",
    "df_Q1.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wat hier uit zichtbaar wordt is:\n",
    "* Acteur 1 heeft veel invloed op total cast likes\n",
    "* Acteur 2 heeft aanzienlijk minder invloed dan acteur 1 op de total cast likes\n",
    "* Movie likes heeft zwak invloed op de omzet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vervolgens is de dataset opgesplitst naar een input(X) en output(y) waar ze vervolgens gesplitst worden naar een train, test en validatie set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data to X and y\n",
    "X = df_Q1.drop(columns=['Gross'])\n",
    "y = df_Q1['Gross']\n",
    "assert len(X) == len(y) # make sure that the length of x is the same as the length of y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create Train test and validation Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Doing it twice because you need a validation set as well\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Q1. Model building\n",
    "\n",
    "Aangezien er zwakke correlatie tussen de input en output is, is een regressie mogelijk.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "LR = LogisticRegression(random_state=1, solver=\"lbfgs\", multi_class=\"auto\", max_iter=200)\n",
    "\n",
    "LR.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoals je ziet geeft hij een Convergence warning en kan het zijn dat deze data niet geschikt is voor een logstic regression model\n",
    "\n",
    "De volgende stap is de waarde van de voorspelling te bepalen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, LR.predict(X_test))\n",
    "rms = math.sqrt(abs(mse))\n",
    "score = LR.score(X_test, y_test)\n",
    "\n",
    "print(\"RMS: {}\".format(rms))\n",
    "print(\"MSE: {}\".format(abs(mse)))\n",
    "print(\"Score: {:.4f}\".format(score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na het bekijken van de scores zie je dat dit een erg slecht model is om dit te voorspellen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression\n",
    "\n",
    "Nu we weten dat een logistic regression model niet werkt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "LR = LinearRegression()\n",
    "\n",
    "LR.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, LR.predict(X_test))\n",
    "rms = math.sqrt(mse)\n",
    "score = LR.score(X_test, y_test)\n",
    "\n",
    "print(\"RMS: {}\".format(rms))\n",
    "print(\"MSE: {}\".format(mse))\n",
    "print(\"Score: {}\".format(score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu er een score is zien je dat dit model het beter doet dan ons logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Data processing\n",
    "\n",
    "Nadat er een base score is van dit model kan je normalisatie toevoegen en kijken wat de invloed hier op is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_scaled = stats.zscore(X)\n",
    "y_scaled = stats.zscore(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nadat we de X data gescaled hebben door middel van een zscores moeten we dit weer op splitsen naar train, test en validatie sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create Train test and validation Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_scaled, y_scaled, test_size=0.2, random_state=1)\n",
    "# Doing it twice because you need a validation set as well\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "LR = LinearRegression()\n",
    "\n",
    "LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, LR.predict(X_test))\n",
    "rms = math.sqrt(mse)\n",
    "score = LR.score(X_test, y_test)\n",
    "\n",
    "print(\"RMS: {}\".format(rms))\n",
    "print(\"MSE: {}\".format(mse))\n",
    "print(\"Score: {}\".format(score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Wat we hier bevinden:\n",
    "* De score is zo goed als gelijk gebleven op vergelijking van de vorige voorspelling met een lineaire regressie\n",
    "* Mean squared error is in vergelijking stevig naar beneden gegaan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, 100, len(y_test))\n",
    "plt.plot(x,y_test, LR.predict(X_test)[:100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomial regression\n",
    "Nu is een polynomial regression optie.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "polynomial_features= PolynomialFeatures(degree=2)\n",
    "x_poly = polynomial_features.fit_transform(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create Train test and validation Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_poly, y_scaled, test_size=0.2, random_state=1)\n",
    "# Doing it twice because you need a validation set as well\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "LR = LinearRegression()\n",
    "\n",
    "LR.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, LR.predict(X_test))\n",
    "rms = math.sqrt(mse)\n",
    "score = LR.score(X_test, y_test)\n",
    "\n",
    "print(\"RMS: {}\".format(rms))\n",
    "print(\"MSE: {}\".format(mse))\n",
    "print(\"Score: {}\".format(score))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dit levert ons een slechter model op. Zo is de MSE omhoog gegaan en de Score naar beneden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Communication\n",
    "#### Q1. Definitieve pipeline\n",
    "Onze definitieve model is een lineaire regressie model waarbij de X en y data gescaled is door middel van z-scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y = df_Q1['Gross']\n",
    "y_scaled = stats.zscore(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create Train test and validation Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_scaled, y_scaled, test_size=0.2, random_state=1)\n",
    "# Doing it twice because you need a validation set as well\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "LR = LinearRegression()\n",
    "\n",
    "LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, LR.predict(X_test))\n",
    "rms = math.sqrt(mse)\n",
    "score = LR.score(X_test, y_test)\n",
    "\n",
    "print(\"RMS: {}\".format(rms))\n",
    "print(\"MSE: {}\".format(mse))\n",
    "print(\"Score: {}\".format(score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_val, LR.predict(X_val))\n",
    "rms = math.sqrt(mse)\n",
    "score = LR.score(X_val, y_val)\n",
    "\n",
    "print(\"RMS: {}\".format(rms))\n",
    "print(\"MSE: {}\".format(mse))\n",
    "print(\"Score: {}\".format(score))\n",
    "print(\"Std: {}\".format( df_Q1.Gross.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, len(y_val), len(y_val))\n",
    "plt.plot(x,y_val, LR.predict(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Conclusie\n",
    "\n",
    "De onderzoeksvraag die beantwoord wordt met behulp van dit model ging als volgt:\n",
    "```\n",
    "In hoeverre is de omzet van een film te voorspellen op basis van de populariteit op Facebook en IMDB zelf?\n",
    "```\n",
    "\n",
    "Na het onderzoek is gebleken dat het niet gelukt is door middel van een regressie model een betrouwbare voorspelling te maken. Als je ziet hierboven is het gelukt om een model te maken die 19% van de tijd een goede voorspelling is. Dit valt onder verwachting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Q2. Genres voorspellen gebaseerd op Plot Keywords\n",
    "De onderzoeksvraag gaat als volgt: \n",
    "> In hoeverre is het mogelijk om op basis van plot keywords te voorspellen tot welke genres een film behoort? \n",
    "\n",
    "\n",
    "### Q2. Data collection\n",
    "Bij `Q2` wordt er gebruik gemaakt van de kolommen `Genres` en `Plot Keywords` uit `df_movies`. Om ervoor te zorgen dat bij andere onderzoeksvragen de DataFrame niet onnodig wordt aangepast, wordt de dataframe voor de zekerheid als een kopie aangeroepen. \n",
    "\n",
    "Ook wordt het model aan het einde van het hoofdstuk getest in een andere scenario. Er wordt getest vanuit de plot beschrijving (I.E. een alinea lange beschrijving van het plot) in plaats van plot keywords. Deze data wordt tegelijkertijd met `DF_Q2` verwerkt tot een X en een Y.\n",
    "\n",
    "Deze extra data komt van [Document Classification](http://www.davidsbatista.net/blog/2017/04/01/document_classification/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_Q2 = df_movies.loc[:, (\"Genres\", \"Plot Keywords\")].copy()\n",
    "df_Q2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Data processing\n",
    "Aangezien vrijwel alle machine learning algoritmen alleen algebraïsche datatypes accepteren, moeten zowel `Plot Keywords` als `Genres` ingrijpend veranderd worden. Beide zijn namelijk categoriale datatypes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2. Cleaning voor processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Na een korte inspectie van de data, kom je een aantal waardes van 0 en “0” tegen (`int` en `string`). Dit zijn missende waarden. \n",
    "\n",
    "Hoewel dit gewoonlijks in stap 3 van het Data Science proces gebeurt, is het in deze scenario beter om dit van tevoren te doen. De 0 en \"0\" zijn na deze stap namelijk moeilijker terug te vinden.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# All '0' are missing values, remove\n",
    "df_Q2.replace(\"0\", np.NaN, inplace=True)\n",
    "df_Q2.replace(0, np.NaN, inplace=True)\n",
    "df_Q2.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2. Terug naar processing\n",
    "Om in de gebruikte modellen gebruik te maken van `Genres` en `Plot Keywords` moeten deze gecodeerd worden. \n",
    "\n",
    "Om dit te doen moeten de kolommen eerst gesplitst worden. Dit gaat op twee manieren. \n",
    "\n",
    "Van `Genres` wordt een lijst gemaakt, alle genres zijn namelijk opgebroken met behulp van een `|`. Dit resulteerd in de kolom `Split Genres`. Hetzelfde proces wordt toegepast bij `Plot Keywords`. Dit resulteerd in de kolom `Split Keywords`.\n",
    "\n",
    "Bij `Plot Keywords` worden alle `|` vervangen met een spatie. Dit wordt later verder toegelicht.\n",
    "\n",
    "Hoewel `Split Keywords` niet wordt gebruikt als input variabele, is deze alsnog handig om te hebben bij het analyseren van de data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Split \"Genres\" by \"|\", creating list types\n",
    "df_Q2.loc[:, \"Split Genres\"] = df_Q2[\"Genres\"].str.split(pat=\"|\")\n",
    "\n",
    "# Replace \"|\" with \" \" to create strings analysable by TF-IDf.\n",
    "df_Q2.loc[:, \"Plot Keywords\"] = df_Q2[\"Plot Keywords\"].str.replace(\"|\", \" \")\n",
    "# Split \"Plot Keywords\" by \" \", creating list types\n",
    "df_Q2.loc[:, \"Split Keywords\"] = df_Q2[\"Plot Keywords\"].str.split(pat=\" \")\n",
    "\n",
    "\n",
    "df_Q2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame([df_Q2[\"Split Genres\"].str.len().describe(), df_Q2[\"Split Keywords\"].str.len().describe()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Er zijn gemiddeld drie genres en vijf plot keywords per film. Het is echter géén uniforme data. Zowel genres als plot keywords heeft een minimum van 1 woord (I.E. er is maar één genre of één plot keyword). Het maximaal aantal waarden voor genres is 8, het maximaal aantal waarden voor plot keywords is daarentegen 25. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Een probleem met de vraagstelling is dat genres multilabel waardes zijn, een film dus heeft meer dan een genre. Alleen het eerste genre pakken is een mogelijkheid, maar dit zal de accuratesse van ons model zeer negatief beïnvloeden. De genres zijn namelijk niet gesorteerd op toepasbaarheid, maar alfabetisch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "alphabetical = True\n",
    "for value in df_Q2[\"Split Genres\"].values:\n",
    "    if value != sorted(value):\n",
    "        alphabetical = False\n",
    "        \n",
    "alphabetical\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zowel genres als plot keywords is categorische data. Aangezien meeste machine learning modellen algebraïsch zijn, accepteren deze alleen numerieke data. Dat betekent dat zowel genres als keywords omgezet moet worden naar numerieke data. \n",
    "\n",
    "Dit wordt meestal doormiddel van ‘One-Hot’ encoding gedaan. Bij 'One-Hot' encoding wordt van iedere unieke waarde een eigen kolom gemaakt. Deze kolom heeft een waarde '1' of '0'. Of de waarde komt voor in `Genres`, of niet.\n",
    "\n",
    "Dit veroorzaakt echter een probleem wanneer er sprake is van een grote variatie aan herhalende data. In deze scenario kan term frequency-inverse document frequency (TF-IDF) gebruikt worden.\n",
    "\n",
    "TF-IDF genereerd namelijk waardes en kolommen gebaseerd op de frequentie van woorden in een string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De volgende stap is om te kijken naar unieke waarden van zowel `Genres` als `Plot Keywords`. Gebaseerd op het aantal unieke waarden wordt de de codeertechniek gekozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "genre_uniques = find_uniques(df_Q2[\"Split Genres\"])\n",
    "genre_uniques.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het gaat hierbij dus om 24 unieke genres. Ook zullen genres niet meer dan één keer in een rij voorkomen. Bij `Genres` zal dus One-Hot encoding gebruikt worden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "key_uniques = find_uniques(df_Q2[\"Split Keywords\"])\n",
    "key_uniques.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Er zijn in totaal 6104 unieke plot keywords. Bepaalde plot keywords zullen ook meerdere keren per rij voor kunnen komen. Bij `Plot Keywords` zal dus TF-IDF gebruikt worden.\n",
    "#### Q2 Coderen van categoriale data\n",
    "Beginnend met `Genres`, deze kolom wordt gecodeerd met behulp van One-Hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_Q2 = one_hot(df_Q2, \"Split Genres\")\n",
    "Y = df_Q2.loc[:, \"Drama\" : ]\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten tweede coderen we `Plot Keywords`, deze kolom wordt gecodeerd met behulp van TF-IDF. \n",
    "TF-IDF kan ook veel gebruikte, maar weinig zeggende woorden (`stop words`) als ‘of’ en ‘and’ uit een tekst halen. Deze worden direct door de TF-IDF-vectorizer van Scikit-learn geëxtraheerd. Hierdoor neemt het aantal kolommen significant af.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(stop_words=stop_words)\n",
    "X = vec.fit_transform(df_Q2[\"Plot Keywords\"])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Hoewel 5994 kolommen nog steeds veel is, bespaar je als nog erg veel in vergelijking tot 6104 kolommen.\n",
    "\n",
    "#### Q2. Processing van extra dataset\n",
    "\n",
    "De data van genres staat al One-Hot gecodeerd. Er zijn hier echter wel meer genres dan bij de originele dataset. De extra genres moeten dus verwijderd worden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Y_genres = df_genres[np.intersect1d(Y.columns.values, df_genres.columns.values)].copy()\n",
    "Y_genres.columns.size, Y.columns.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Er mist nu nog één genre in `Y_genres`. Deze zal overal gelijk staan aan 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "missing_genre = np.setdiff1d(Y.columns.values, Y_genres.columns.values)\n",
    "print(\"Missing genre:\", missing_genre[0])\n",
    "Y_genres.loc[:, missing_genre[0]] = 0\n",
    "Y_genres = Y_genres[Y.columns.values]\n",
    "Y_genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Y_genres.columns == Y.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vervolgens moet ook de X van `DF_genres` verwerkt worden. Bij de bron van de dataset moet er eerst gefilterd worden op taal. Hier is dat niet nodig, aangezien de TF-IDF vectorizer gefit is op een Engelse dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_genres = vec.transform(df_genres[\"plot\"])\n",
    "X_genres.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Data cleaning\n",
    "Al het Data Cleaning is voor deze stap al gedaan, namelijk in de paragrafen `3. Data Cleaning` en `Q2. Cleaning voor processing`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Data Exploration & Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu is een goed moment om te kijken naar de X en Y (noteer de hoofdletter bij Y, de output is namelijk ook een matrix). Beginnend met de X.\n",
    "\n",
    "De X moet wel eerst omgevormd worden naar een NumPy array. X wordt nu namelijk nog opgeslagen in de vorm van een sparse array. Dit om ruimte in het geheugen te besparen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(X.toarray(), columns=vec.get_feature_names()).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier valt al direct een probleem te ontdekken, de waardes gegenereerd door TF-IDF liggen redelijk laag. Dit betekent dat er niet veel van dezelfde woorden langskomen. Dit kán mogelijk de waarde van de voorspellingen negatief beïnvloeden. Hier wordt echter tot zekere hoogte rekening mee gehouden met behulp van het gebruik van `stop_words`.\n",
    "\n",
    "Vervolgens de Y. Aangezien er een eigen One-Hot functie geschreven is, wordt Y niet opgeslagen in de vorm van een sparse array. Y is in de vorm van een DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Y.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aangezien alle waarden of `1` of `0` zijn, staat het gemiddelde ook gelijk aan het percentage films dit genre tot behoort. Zowel té hoog als té laag zal waarschijnlijk een slechte invloed hebben op de voorspellingen. \n",
    "\n",
    "Aangezien iets meer dan 50% van de films behoren tot het genre `Drama` behoren, zal er waarschijnlijk sprake zijn van veel false positives. \n",
    "\n",
    "Ook zijn er een groot aantal genres waar minder dan 5% van de films tot behoren. Aangezien hier relatief weinig data van is, zal het verbanden vinden tussen plot keywords en deze genres aanzienlijk moeilijker zijn. Waarschijnlijk zal er sprake zijn van veel false negatives. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra data set\n",
    "Tenslotte wordt er ook nog gekeken naar het aantal films per genre bij de extra dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "unique_extra = pd.DataFrame(Y_genres.sum(), columns=[\"Count\"])\n",
    "unique_extra.reset_index(inplace=True)\n",
    "unique_extra.columns = [\"Split Genres\", \"Test Count\"]\n",
    "\n",
    "unique_extra = unique_extra.merge(genre_uniques)\n",
    "unique_extra.columns = [\"Split Genres\", \"Test Count\", \"Train Count\"]\n",
    "unique_extra.sort_values(\"Test Count\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Model building\n",
    "\n",
    "\n",
    "Films zoals “[Bad Boys](https://www.imdb.com/title/tt0112442/?ref_=ttkw_kw_tt)” met genres als ‘Action, Comedy, Crime’ zullen dan alleen geclassificeerd worden als ‘Action’. [Plot keywords](https://www.imdb.com/title/tt0112442/keywords?ref_=tt_ql_stry_4) zoals ‘evil man’ en ‘firearm’ komen dan nog goed overeen met het genre, maar plot keywords als ‘buddy movie’ en ‘buddy comedy’ niet.\n",
    "\n",
    "Om dit op te lossen, moet er gebruik gemaakt worden van ‘multi-label classification’. Dit is niet te verwarren met ‘multi-class classification’. Bij multi-label is er sprake van meerdere labels die tegelijkertijd toepasbaar kunnen zijn, bij multi-class is er altijd maar één klasse(label) toepasbaar.\n",
    "\n",
    "\n",
    "Er worden voor deze onderzoeksvraag drie modellen toegelicht.\n",
    "\n",
    "Ieder model wordt op drie manieren getest:\n",
    "* Accuracy Score per genre (> == beter)\n",
    "* Precision Score per genre (> == beter)\n",
    "* Hamming loss op de gehele voorspelling (< == beter)\n",
    "\n",
    "Tenslotte wordt de hoeveelheid films per genre als extra kolom toegevoegd.\n",
    "\n",
    "Ten eerste, het opsplitsen in `test` en `train` datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=42)\n",
    "print(\"Train:\", X_train.shape, Y_train.shape)\n",
    "print(\"Test:\", X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2. Imiteren met behulp van Multi-Class predictions\n",
    "Eén methode om multi-label te implementeren, is om dit niet te doen. In plaats van “echte” multi-label classificatie te gebruiken, imiteer je het met behulp van Multi-Class classificatie. Voor iedere klasse train en test je het model apart. Dit komt echter met een forse performance hit. Ook zorgt dit ervoor dat voor iedere test set opnieuw het model moet laten fitten.\n",
    "\n",
    "Qua model wordt er hier gebruik gemaakt van een Multinomial Naive Bayesian model, met daar omheen een veel gebruikte Multi-Class wrapper (OneVsRest). Multinomial Naive Bayesian is vrijwel de standaard voor text classificatie, en zal waarschijnlijk het eerste resultaat zijn indien je text classificatie googled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "NB_pipeline = Pipeline([\n",
    "                ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "                    fit_prior=True, class_prior=None))),\n",
    "            ])\n",
    "\n",
    "predictions = []\n",
    "for genre in genre_uniques[\"Split Genres\"]:\n",
    "    NB_pipeline.fit(X_train, Y_train[genre])\n",
    "    predictions.append(NB_pipeline.predict(X_test))\n",
    "   \n",
    "predictions = np.array(predictions).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Hamming loss:\", hamming_loss(Y_test, predictions))\n",
    "column_score(Y_test, predictions).merge(genre_uniques, left_on=\"Category\", right_on=\"Split Genres\").drop(\"Split Genres\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De waarde van de voorspelling lijkt beter te worden naarmate het aantal films per genre het gemiddeld aantal films per genre (564, zie Q2. Data processing) bereikt. Zodra het aantal films hier ruim onder begint te komen, voorspelt dit model dat alle films tot die genres behoren.\n",
    "\n",
    "De Hamming loss van dit model ligt erg laag, op ongeveer 0.11. Dat betekent dat de voorspeling van redelijk goede kwaliteit is.  \n",
    "\n",
    "\n",
    "#### Q2. Binary Relevance en Naive Bayes classifiers\n",
    "De tweede methode om multi-label classification toe te passen, heet Binary Relevance. Dit valt beter uit te leggen met behulp van een voorbeeld. Zie daarvoor de volgende paragraaf. Binary Relevance is op moment van schrijven nog niet opgenomen in het officiële Scikit-Learn library. Om dit te kunnen gebruiken is de Scikit-Learn addon ` skmultilearn` benodigd.\n",
    "##### Multinomial\n",
    "Hieronder wordt net zoals bij `Q2. Imiteren met behulp van Multi-Class predictions` gebruik gemaakt van Multinomiale Naive Bayesian classificatie. Met de `BinaryRelevance` wrapper van `skmultilearn` er omheen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "MNB_classifier = BinaryRelevance(MultinomialNB())\n",
    "MNB_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictions = MNB_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Hamming loss:\", hamming_loss(Y_test, predictions))\n",
    "df_MNB_score = column_score(Y_test, predictions).merge(genre_uniques, left_on=\"Category\", right_on=\"Split Genres\").drop(\"Split Genres\", axis=1)\n",
    "df_MNB_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De resultaten van Binary Relevance op Multinomial NB zijn exact hetzelfde als de resultaten resultaten van de eerder gebruikte pipeline. \n",
    "\n",
    "Binary Relevance valt binnen multi-label machine learning in het groepje `Problem transformation approaches`. Het pakt een multi-label probleem, en splitst deze op in kleinere problemen die op te lossen zijn met behulp van al bestaande technieken. \n",
    "Een nadeel hiervan is echter wel dat de verbanden tússen de verschillende labels buiten beschouwing raken. Het resultaat is desalniettemin beter dan verwacht.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gaussian naive bayes\n",
    "\n",
    "Een tweede model dat regelmatig wordt gebruikt voor het classificeren van tekst, is het Gaussian Naive Bayes model. Dit gaat uit van een normaalverdeling in plaats van een multinomiale verdeling.\n",
    "\n",
    "Gaussian is meestal een aanzienlijk slechtere methode om tekst mee te classificeren, het wordt bij deze onderzoeksvraag alleen gebruikt om de kwaliteit van Multinomial Naive Bayes beter te laten zien.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "GNB_classifier = BinaryRelevance(GaussianNB())\n",
    "GNB_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictions = GNB_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Hamming loss:\", hamming_loss(Y_test, predictions))\n",
    "df_GNB_score = column_score(Y_test, predictions).merge(genre_uniques, left_on=\"Category\", right_on=\"Split Genres\").drop(\"Split Genres\", axis=1)\n",
    "df_GNB_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoals verwacht is de voorspelling minder accuraat dan die van Multinomial NB. De voorspelling is echter wel beter dan verwacht. Het is beter in het voorspellen van de waardes die onder het gemiddelde vallen dan Multinomial NB, voor alle andere waarden lijkt het echter slechter te zijn. \n",
    "\n",
    "Tenslotte zijn de laatste drie genres (Film-Noir, Short & News) alle drie nog steeds niet mogelijk om te voorspellen.\n",
    "\n",
    "#### Q2. Model testing; Extra dataset\n",
    "\n",
    "Tenslotte wordt dezelfde voorspelling nog een keer uitgevoerd op de extra dataset. Hier wordt weer gebruik gemaakt van de Multinomial Naive Bayesian classifier uit `Q2. Multinomial`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictions = MNB_classifier.predict(X_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Hamming loss:\", hamming_loss(Y_genres, predictions))\n",
    "df_extra_score = column_score(Y_genres, predictions).merge(unique_extra, left_on=\"Category\", right_on=\"Split Genres\").drop(\"Split Genres\", axis=1)\n",
    "df_extra_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoewel de Hamming loss lager is dan bij de andere voorspellingen, is de precision score aanzienlijk slechter. De mindere waarde is op een paar manieren te verklaren.\n",
    "\n",
    "De grootte van de originele dataset was te klein om op te trainen. Deze externe dataset is completer, maar daar wordt geen rekening mee gehouden bij het TF-IDF-proces. Er zullen waarschijnlijk veel termen voorkomen in de externe dataset, die niet voorkomen in de originele dataset.\n",
    "\n",
    "De aard van de externe data is anders dan van het origineel. De externe data bestaat uit een uitgebreide beschrijving van het plot. De originele dataset bevat meerdere enkele termen of korte zinnen. Het kan zijn dat ‘keywords’ zodanig anders zijn dan een beschrijving van het plot, dat dat de voorspelling aanzienlijk negatief beïnvloed.\n",
    "\n",
    "Het lijkt echter wel dat deze voorspelling hetzelfde pattern volgt als de voorspelling op de testdata. De precision wordt langzamerhand beter totdat deze het genre met het gemiddeld aantal films bereikt. Wanneer het onder dit gemiddelde valt, wordt de precision score 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Visualization\n",
    "Om een beter beeld te geven van de verbanden tussen het aantal films per genre, en hun accuracy- en precision scores, worden deze samen geplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sc_MNB_ac = hv.Scatter(df_MNB_score[[\"Count\", \"Accuracy Score\"]]).opts(title=\"MNB\", ylim=(-0.05, 1.05), xlim=(-100, 2500), size=5)\n",
    "sc_GNB_ac = hv.Scatter(df_GNB_score[[\"Count\", \"Accuracy Score\"]]).opts(title=\"GNB\", ylim=(-0.05, 1.05), xlim=(-100, 2500), size=5)\n",
    "sc_extra_ac = hv.Scatter(df_extra_score[[\"Train Count\", \"Accuracy Score\"]]).opts(title=\"Extra MNB\", ylim=(-0.05, 1.05), xlim=(-100, 2500), size=5)\n",
    "\n",
    "\n",
    "sc_MNB_pr = hv.Scatter(df_MNB_score[[\"Count\", \"Precision Score\"]]).opts(title=\"MNB\", ylim=(-0.05, 1.05), xlim=(-100, 2500), size=5)\n",
    "sc_GNB_pr = hv.Scatter(df_GNB_score[[\"Count\", \"Precision Score\"]]).opts(title=\"GNB\", ylim=(-0.05, 1.05), xlim=(-100, 2500), size=5)\n",
    "sc_extra_pr = hv.Scatter(df_extra_score[[\"Train Count\", \"Precision Score\"]]).opts(title=\"Extra MNB\", ylim=(-0.05, 1.05), xlim=(-100, 2500), size=5)\n",
    "\n",
    "\n",
    "(sc_MNB_pr + sc_GNB_pr + sc_extra_pr + sc_MNB_ac + sc_GNB_ac + sc_extra_ac).cols(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Communication\n",
    "#### Q2. Definitieve pipeline\n",
    "De definitieve pipeline van dit project is de `MNB_classifier`. De Binary Relevance Multinomial Naive Bayesian classifier. Van de twee classificatie modellen, geeft deze betere voorspellingen.\n",
    "#### Q2. Conclusie\n",
    "De onderzoeksvraag die beantwoord wordt met behulp van dit model ging als volgt:\n",
    "> In hoeverre is het mogelijk om op basis van plot keywords te voorspellen tot welke genres een film behoort?\n",
    "\n",
    "Het is zeer goed mogelijk om op basis van plot keywords te voorspellen tot welke genres een film behoort. Er zijn echter wel een paar dingen waar, bij dit model, rekening mee gehouden moet worden. \n",
    "Ten eerste is het model, met de huidige training data, niet goed in het voorspellen van genres met minder dan 515 datapunten. Dat houdt dat maar 10 van de 24 genres correct voorspeld kunnen worden. \n",
    "\n",
    "De meeste films zullen in principe behoren tot die 10 genres, maar dat betekent niet dat er geen films van die genres bestaan. Bij een dataset van circa 5000 films is dit nog geen groot probleem, bij volledigere datasets (denk aan 100K+) zal dit echter wél voor een probleem veroorzaken.\n",
    "\n",
    "Ten tweede houdt dit model geen rekening met de onderlinge verbanden tussen genres. Een film behorend tot het genre ‘Biography’ zal vaak ook behoren tot het genre ‘Documentary’. \n",
    "\n",
    "#### Q2. Mogelijk vervolg onderzoeken\n",
    "\n",
    "Bij een mogelijk vervolgonderzoek komen een aantal dingen aan bod. Ten eerste zou dit onderzoek opnieuw uitgevoerd moeten worden op een andere, grotere dataset. \n",
    "\n",
    "Ten tweede zou er gekeken moeten worden naar meer geavanceerde multi-label classificatie methoden die wél rekening houden met de onderlinge verbanden tussen genres.\n",
    "\n",
    "Ten derde zou er gekeken moeten worden naar de verschillen tussen een plot beschrijving (zoals van de externe dataset) en plot keywords (van de originele dataset).\n",
    "\n",
    "\n",
    "#### Q2 Extra leesmateriaal\n",
    "[TF-IDF](http://www.tfidf.com)\n",
    "\n",
    "[Understanding Multi-Label classification model and accuracy metrics](https://medium.com/towards-artificial-intelligence/understanding-multi-label-classification-model-and-accuracy-metrics-1b2a8e2648ca)\n",
    "\n",
    "[Multi Label Text Classification with Scikit-Learn](https://towardsdatascience.com/multi-label-text-classification-with-scikit-learn-30714b7819c5)\n",
    "\n",
    "[Binary relevance for multi-label learning: an overview](https://link.springer.com/article/10.1007/s11704-017-7031-7)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
